# BGE-M3 æœ¬åœ°æœåŠ¡ä½¿ç”¨æŒ‡å—

## âœ… å®Œæˆçš„ä¿®æ”¹

### 1. æ¨¡å‹è·¯å¾„é…ç½®
- **ä¿®æ”¹æ–‡ä»¶**: `serve_bge_m3.py`
- **å˜æ›´å†…å®¹**:
  - `MODEL_ID`: `"BAAI/bge-m3"` â†’ `"/opt/bge-m3/models/bge-m3"`
  - æ·»åŠ  `local_files_only=True` å‚æ•°ï¼Œç¦æ­¢ç½‘ç»œä¸‹è½½

### 2. æœ¬åœ°æ¨¡å‹éªŒè¯
- âœ… PyTorch æƒé‡: `pytorch_model.bin` (2.2GB)
- âœ… é…ç½®æ–‡ä»¶: `config.json`
- âœ… åˆ†è¯å™¨: `tokenizer.json`, `sentencepiece.bpe.model`
- âœ… æ‰€æœ‰å¿…éœ€æ–‡ä»¶é½å…¨

---

## ğŸš€ å¯åŠ¨æœåŠ¡

### æ–¹å¼ä¸€: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
cd /opt/bge-m3
./start_service.sh
```

### æ–¹å¼äºŒ: æ‰‹åŠ¨å‘½ä»¤
```bash
cd /opt/bge-m3
source .venv/bin/activate
CUDA_VISIBLE_DEVICES=0 uvicorn serve_bge_m3:app --host 0.0.0.0 --port 8001 --workers 1
```

### å‚æ•°è¯´æ˜
- `CUDA_VISIBLE_DEVICES=0`: ä½¿ç”¨ GPU 0
- `--host 0.0.0.0`: ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£
- `--port 8001`: æœåŠ¡ç«¯å£
- `--workers 1`: å•è¿›ç¨‹ï¼ˆæ¨èï¼Œé¿å…æ¨¡å‹é‡å¤åŠ è½½ï¼‰

---

## ğŸ§ª æµ‹è¯•æœåŠ¡

### æ–¹å¼ä¸€: ä½¿ç”¨æµ‹è¯•è„šæœ¬
```bash
# å¯åŠ¨æœåŠ¡åï¼Œåœ¨æ–°ç»ˆç«¯è¿è¡Œï¼š
cd /opt/bge-m3
python test_client.py
```

### æ–¹å¼äºŒ: ä½¿ç”¨ curl
```bash
curl -X POST http://localhost:8001/embed \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ?", "Machine learning is AI"],
    "output_type": "dense",
    "normalize": true,
    "max_length": 512
  }'
```

### æ–¹å¼ä¸‰: Python ä»£ç 
```python
import requests

response = requests.post(
    "http://localhost:8001/embed",
    json={
        "texts": ["æµ‹è¯•æ–‡æœ¬1", "æµ‹è¯•æ–‡æœ¬2"],
        "normalize": True
    }
)

embeddings = response.json()["embeddings"]
print(f"å‘é‡ç»´åº¦: {len(embeddings[0])}")  # åº”è¾“å‡º 1024
```

---

## ğŸ“Š API å‚è€ƒ

### POST /embed

**è¯·æ±‚ä½“**:
```json
{
  "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2"],      // å¿…éœ€: å¾…åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨
  "output_type": "dense",           // é»˜è®¤: "dense" (å½“å‰ä»…æ”¯æŒ dense)
  "normalize": true,                // é»˜è®¤: true (å‘é‡å½’ä¸€åŒ–)
  "max_length": 512,                // é»˜è®¤: 512 (æœ€å¤§æ”¯æŒ 8192)
  "batch_size": 32                  // é»˜è®¤: 32 (æ‰¹å¤„ç†å¤§å°)
}
```

**å“åº”ä½“**:
```json
{
  "embeddings": [
    [0.123, -0.456, ...],  // 1024 ç»´å‘é‡
    [0.789, 0.234, ...]
  ]
}
```

---

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPU ä½¿ç”¨
- é»˜è®¤å¯ç”¨ CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
- è‡ªåŠ¨ä½¿ç”¨ FP16 ç²¾åº¦ï¼ˆèŠ‚çœæ˜¾å­˜ 50%ï¼‰
- CPU æ¨¡å¼è‡ªåŠ¨é™çº§ä¸º FP32

### 2. æ‰¹å¤„ç†é…ç½®
```python
# å°æ‰¹é‡ã€ä½å»¶è¿Ÿ
{"batch_size": 8, "max_length": 256}

# å¤§æ‰¹é‡ã€é«˜åå
{"batch_size": 64, "max_length": 512}

# é•¿æ–‡æ¡£å¤„ç†
{"batch_size": 4, "max_length": 8192}
```

### 3. å¤š GPU éƒ¨ç½²
```bash
# GPU 0
CUDA_VISIBLE_DEVICES=0 uvicorn serve_bge_m3:app --port 8001 --workers 1

# GPU 1
CUDA_VISIBLE_DEVICES=1 uvicorn serve_bge_m3:app --port 8002 --workers 1
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1: æ¨¡å‹åŠ è½½å¤±è´¥
```
FileNotFoundError: /opt/bge-m3/models/bge-m3/config.json
```
**è§£å†³**: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
```bash
ls -lh /opt/bge-m3/models/bge-m3/
```

### é—®é¢˜2: CUDA å†…å­˜ä¸è¶³
```
RuntimeError: CUDA out of memory
```
**è§£å†³**: å‡å° batch_size æˆ– max_length

### é—®é¢˜3: ç«¯å£è¢«å ç”¨
```
OSError: [Errno 98] Address already in use
```
**è§£å†³**: æ›´æ¢ç«¯å£æˆ–æ€æ­»å ç”¨è¿›ç¨‹
```bash
lsof -i :8001
kill -9 <PID>
```

---

## ğŸ“ æ–‡ä»¶æ¸…å•

- âœ… `serve_bge_m3.py` - ä¸»æœåŠ¡æ–‡ä»¶ï¼ˆå·²ä¿®æ”¹ï¼‰
- âœ… `start_service.sh` - å¯åŠ¨è„šæœ¬ï¼ˆæ–°å¢ï¼‰
- âœ… `test_client.py` - æµ‹è¯•å®¢æˆ·ç«¯ï¼ˆæ–°å¢ï¼‰
- âœ… `USAGE.md` - æœ¬æ–‡æ¡£ï¼ˆæ–°å¢ï¼‰
- âœ… `models/bge-m3/` - æœ¬åœ°æ¨¡å‹ç›®å½•

---

## ğŸ”— ç›¸å…³èµ„æº

- æ¨¡å‹ä»“åº“: https://huggingface.co/BAAI/bge-m3
- FastAPI æ–‡æ¡£: http://localhost:8001/docs (æœåŠ¡å¯åŠ¨åè®¿é—®)
- æ¨¡å‹è®ºæ–‡: BGE M3-Embedding (Multi-lingual, Multi-functional, Multi-granularity)
