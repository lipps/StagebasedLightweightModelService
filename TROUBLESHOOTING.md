# BGE-M3 æœåŠ¡æ•…éšœæ’æŸ¥å®Œæ•´è®°å½•

## ğŸ”´ é‡åˆ°çš„é—®é¢˜

### é—®é¢˜ 1: å‚æ•°å¼ƒç”¨è­¦å‘Š
```
`torch_dtype` is deprecated! Use `dtype` instead!
```
**å½±å“**: è­¦å‘Šçº§åˆ«ï¼Œä¸å½±å“åŠŸèƒ½

### é—®é¢˜ 2: PyTorch å®‰å…¨æ¼æ´ï¼ˆä¸»è¦é—®é¢˜ï¼‰
```
ValueError: Due to a serious vulnerability issue in `torch.load`,
even with `weights_only=True`, we now require users to upgrade torch
to at least v2.6 in order to use the function.
```

**æ ¹æœ¬åŸå› **:
- **å½“å‰ PyTorch ç‰ˆæœ¬**: 2.3.0+cu121
- **Transformers è¦æ±‚**: â‰¥ 2.6ï¼ˆå› å®‰å…¨æ¼æ´ CVE-2025-32434ï¼‰
- **æ¨¡å‹æ ¼å¼**: pytorch_model.binï¼ˆä¸å®‰å…¨çš„ pickle æ ¼å¼ï¼‰

### é—®é¢˜ 3: GPU ä¸å…¼å®¹
```
NVIDIA GeForce RTX 5090 with CUDA capability sm_120 is not compatible
with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities:
sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
```

**æ ¹æœ¬åŸå› **:
- **RTX 5090 è®¡ç®—èƒ½åŠ›**: sm_120 (CUDA Compute Capability 12.0)
- **PyTorch 2.3.0 æ”¯æŒ**: ä»…åˆ° sm_90
- **ç»“æœ**: CUDA kernel æ— æ³•åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œ

---

## âœ… å·²å®æ–½çš„è§£å†³æ–¹æ¡ˆ

### è§£å†³æ–¹æ¡ˆ 1: è½¬æ¢æ¨¡å‹ä¸º SafeTensors æ ¼å¼

**æ“ä½œ**:
```bash
python convert_to_safetensors.py
```

**ç»“æœ**:
- âœ… ç”Ÿæˆ `/opt/bge-m3/models/bge-m3/model.safetensors` (2.2GB)
- âœ… ç»•è¿‡ torch.load å®‰å…¨æ£€æŸ¥
- âœ… Transformers è‡ªåŠ¨ä¼˜å…ˆåŠ è½½ safetensors æ–‡ä»¶

**ä¼˜ç‚¹**:
- æ— éœ€å‡çº§ PyTorch
- æ›´å®‰å…¨ï¼ˆæ—  pickle ååºåˆ—åŒ–æ¼æ´ï¼‰
- åŠ è½½é€Ÿåº¦æ›´å¿«ï¼ˆä½¿ç”¨å†…å­˜æ˜ å°„ï¼‰

### è§£å†³æ–¹æ¡ˆ 2: å¼ºåˆ¶ä½¿ç”¨ CPU æ¨¡å¼

**ä¿®æ”¹æ–‡ä»¶**: `serve_bge_m3.py`

**å˜æ›´**:
```python
# ä¿®æ”¹å‰
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DTYPE = torch.float16 if DEVICE == "cuda" else torch.float32

# ä¿®æ”¹å
DEVICE = "cpu"  # ä¸´æ—¶å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆRTX 5090 éœ€è¦ PyTorch 2.6+ï¼‰
DTYPE = torch.float32
```

**ç»“æœ**:
- âœ… æœåŠ¡æˆåŠŸå¯åŠ¨
- âœ… API æ­£å¸¸å·¥ä½œï¼ˆå·²æµ‹è¯•ï¼‰
- âš ï¸  æ€§èƒ½é™ä½ï¼ˆCPU æ¨¡å¼ï¼‰

---

## ğŸ“Š æµ‹è¯•éªŒè¯

### å¯åŠ¨æœåŠ¡
```bash
./start_service.sh
# æˆ–
source .venv/bin/activate
uvicorn serve_bge_m3:app --host 0.0.0.0 --port 8001 --workers 1
```

### API æµ‹è¯•
```bash
curl -X POST http://localhost:8001/embed \
  -H "Content-Type: application/json" \
  -d '{"texts": ["æµ‹è¯•æ–‡æœ¬"], "normalize": true}'
```

**æµ‹è¯•ç»“æœ**:
```json
{
  "embeddings": [[...1024ä¸ªæµ®ç‚¹æ•°...]]
}
```
âœ… **éªŒè¯é€šè¿‡ï¼**

---

## ğŸš€ æ€§èƒ½å¯¹æ¯”

| æ¨¡å¼ | æ¨ç†æ—¶é—´ (å•æ–‡æœ¬) | æ‰¹å¤„ç†åå (32 batch) | æ˜¾å­˜å ç”¨ |
|------|-----------------|---------------------|---------|
| **CPU (å½“å‰)** | ~200-500ms | ~2-5 æ–‡æœ¬/ç§’ | 0 GB |
| **GPU (FP16)** | ~10-30ms | ~50-200 æ–‡æœ¬/ç§’ | ~3 GB |

---

## ğŸ”§ é•¿æœŸè§£å†³æ–¹æ¡ˆ

### é€‰é¡¹ A: å‡çº§ PyTorch ä»¥æ”¯æŒ RTX 5090ï¼ˆæ¨èï¼‰

#### 1. å®‰è£…æ”¯æŒ CUDA 12.8+ çš„ PyTorch 2.6+

**æ£€æŸ¥æœ€æ–°ç‰ˆæœ¬**:
```bash
# è®¿é—® https://pytorch.org/get-started/locally/
# é€‰æ‹©: Linux, Pip, Python, CUDA 12.8
```

**å®‰è£…å‘½ä»¤ç¤ºä¾‹**:
```bash
source .venv/bin/activate
pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

#### 2. éªŒè¯å®‰è£…
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

#### 3. æ¢å¤ GPU æ¨¡å¼
ä¿®æ”¹ `serve_bge_m3.py`:
```python
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DTYPE = torch.float16 if DEVICE == "cuda" else torch.float32
```

**é¢„æœŸæ”¶ç›Š**:
- âœ… **10-20 å€æ€§èƒ½æå‡**
- âœ… FP16 ç²¾åº¦åŠ é€Ÿ
- âœ… æ‰¹å¤„ç†ååæå‡åˆ° ~50-200 æ–‡æœ¬/ç§’

---

### é€‰é¡¹ B: ç»§ç»­ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰

**é€‚ç”¨åœºæ™¯**:
- å¼€å‘æµ‹è¯•ç¯å¢ƒ
- ä½å¹¶å‘æœåŠ¡ï¼ˆ<10 QPSï¼‰
- é¿å…ç¯å¢ƒç ´å

**ä¼˜åŒ–å»ºè®®**:
```python
# å¢åŠ  CPU çº¿ç¨‹æ•°ï¼ˆä¿®æ”¹ serve_bge_m3.pyï¼‰
torch.set_num_threads(4)  # åŸå€¼ä¸º 1

# è°ƒæ•´æ‰¹å¤„ç†å¤§å°
batch_size = 8  # é™ä½æ‰¹å¤„ç†å‡å°‘å»¶è¿Ÿ
```

---

### é€‰é¡¹ C: ä½¿ç”¨ ONNX Runtimeï¼ˆä¸­ç­‰æ€§èƒ½ï¼‰

ONNX Runtime å¯¹ CPU æœ‰æ›´å¥½çš„ä¼˜åŒ–ï¼š

#### 1. å®‰è£… ONNX Runtime
```bash
source .venv/bin/activate
pip install onnxruntime
```

#### 2. ä½¿ç”¨ç°æœ‰ ONNX æ¨¡å‹
æ¨¡å‹è·¯å¾„: `/opt/bge-m3/models/bge-m3/onnx/`

#### 3. ä¿®æ”¹åŠ è½½ä»£ç ï¼ˆéœ€è¦é‡å†™æœåŠ¡ï¼‰
```python
from optimum.onnxruntime import ORTModelForFeatureExtraction

model = ORTModelForFeatureExtraction.from_pretrained(
    MODEL_ID,
    provider="CPUExecutionProvider"
)
```

**é¢„æœŸæ”¶ç›Š**:
- âœ… CPU æ€§èƒ½æå‡ **2-3 å€**
- âœ… å†…å­˜å ç”¨å‡å°‘ ~30%
- âš ï¸  éœ€è¦é‡å†™æ¨ç†ä»£ç 

---

## ğŸ“‹ æ–‡ä»¶å˜æ›´æ¸…å•

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `serve_bge_m3.py` | âœï¸ å·²ä¿®æ”¹ | å¼ºåˆ¶ CPU æ¨¡å¼ |
| `models/bge-m3/model.safetensors` | ğŸ†• æ–°å¢ | å®‰å…¨æ¨¡å‹æ ¼å¼ |
| `convert_to_safetensors.py` | ğŸ†• æ–°å¢ | æ ¼å¼è½¬æ¢è„šæœ¬ |
| `start_service.sh` | ğŸ†• æ–°å¢ | å¯åŠ¨è„šæœ¬ |
| `test_client.py` | ğŸ†• æ–°å¢ | API æµ‹è¯•å®¢æˆ·ç«¯ |
| `TROUBLESHOOTING.md` | ğŸ†• æ–°å¢ | æœ¬æ–‡æ¡£ |

---

## ğŸ¯ æ¨èæ“ä½œæµç¨‹

### ç«‹å³å¯ç”¨ï¼ˆå½“å‰çŠ¶æ€ï¼‰
```bash
# 1. å¯åŠ¨æœåŠ¡ï¼ˆCPU æ¨¡å¼ï¼‰
./start_service.sh

# 2. æµ‹è¯• API
python test_client.py
```

### æœ€ä½³å®è·µï¼ˆå»ºè®®å‡çº§åï¼‰
```bash
# 1. å‡çº§ PyTorch åˆ° 2.6+
pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu128

# 2. æ¢å¤ GPU æ¨¡å¼ï¼ˆä¿®æ”¹ serve_bge_m3.pyï¼‰
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 3. é‡å¯æœåŠ¡
./start_service.sh

# 4. éªŒè¯ GPU åŠ é€Ÿ
python -c "import torch; print(torch.cuda.get_device_name(0))"
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **SafeTensors ä¼˜å…ˆçº§**: Transformers ä¼šè‡ªåŠ¨ä¼˜å…ˆåŠ è½½ `.safetensors` æ–‡ä»¶ï¼Œå³ä½¿ `pytorch_model.bin` ä»ç„¶å­˜åœ¨

2. **åˆ é™¤æ—§æ¨¡å‹**ï¼ˆå¯é€‰ï¼‰:
   ```bash
   # èŠ‚çœ 2.2GB ç©ºé—´
   rm /opt/bge-m3/models/bge-m3/pytorch_model.bin
   ```

3. **å¤‡ä»½å½“å‰ç¯å¢ƒ**ï¼ˆå‡çº§å‰ï¼‰:
   ```bash
   pip freeze > requirements_backup.txt
   ```

4. **PyTorch ç‰ˆæœ¬å…¼å®¹æ€§**:
   - PyTorch 2.6+ éœ€è¦ CUDA 12.1+
   - æ£€æŸ¥ç³»ç»Ÿ CUDA ç‰ˆæœ¬: `nvcc --version`

---

## ğŸ“ è·å–å¸®åŠ©

- **PyTorch å®˜æ–¹æ–‡æ¡£**: https://pytorch.org/get-started/locally/
- **Transformers æ–‡æ¡£**: https://huggingface.co/docs/transformers
- **BGE-M3 æ¨¡å‹å¡ç‰‡**: https://huggingface.co/BAAI/bge-m3
- **CVE-2025-32434 è¯¦æƒ…**: https://nvd.nist.gov/vuln/detail/CVE-2025-32434
