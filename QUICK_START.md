# BGE-M3 å¿«é€Ÿå¯åŠ¨æŒ‡å—

## âœ… å½“å‰çŠ¶æ€ï¼šå¯ç”¨ï¼ˆCPU æ¨¡å¼ï¼‰

### ğŸš€ ç«‹å³å¯åŠ¨

```bash
cd /opt/bge-m3
./start_service.sh
```

æœåŠ¡å°†åœ¨ http://localhost:8001 å¯åŠ¨

---

## ğŸ§ª å¿«é€Ÿæµ‹è¯•

```bash
# æ–¹å¼1: ä½¿ç”¨æµ‹è¯•è„šæœ¬
python test_client.py

# æ–¹å¼2: ä½¿ç”¨ curl
curl -X POST http://localhost:8001/embed \
  -H "Content-Type: application/json" \
  -d '{"texts": ["æµ‹è¯•"], "normalize": true}'
```

---

## ğŸ“Š å½“å‰é…ç½®

| é¡¹ç›® | å€¼ |
|------|-----|
| **è¿è¡Œæ¨¡å¼** | CPUï¼ˆä¸´æ—¶ï¼‰ |
| **æ¨¡å‹è·¯å¾„** | `/opt/bge-m3/models/bge-m3` |
| **æ¨¡å‹æ ¼å¼** | SafeTensorsï¼ˆå®‰å…¨ï¼‰ |
| **PyTorch** | 2.3.0+cu121 |
| **ç«¯å£** | 8001 |
| **å‘é‡ç»´åº¦** | 1024 |

---

## âš¡ æ€§èƒ½æå‡æ–¹æ¡ˆ

### RTX 5090 ç”¨æˆ·å¿…è¯»ï¼

**é—®é¢˜**: å½“å‰ PyTorch 2.3.0 ä¸æ”¯æŒ RTX 5090 GPU

**è§£å†³**: å‡çº§åˆ° PyTorch 2.6+

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate

# 2. å‡çº§ PyTorchï¼ˆè®¿é—®å®˜ç½‘è·å–æœ€æ–°å‘½ä»¤ï¼‰
# https://pytorch.org/get-started/locally/
pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu128

# 3. ä¿®æ”¹ serve_bge_m3.py (ç¬¬12-13è¡Œ)
# å°†ï¼š
#   DEVICE = "cpu"
# æ”¹ä¸ºï¼š
#   DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 4. é‡å¯æœåŠ¡
./start_service.sh
```

**æ€§èƒ½å¯¹æ¯”**:
- CPU æ¨¡å¼: ~200-500ms/æ–‡æœ¬
- GPU æ¨¡å¼: ~10-30ms/æ–‡æœ¬ **(10-20å€æå‡)**

---

## ğŸ“– API ä½¿ç”¨ç¤ºä¾‹

### Python å®¢æˆ·ç«¯

```python
import requests

response = requests.post(
    "http://localhost:8001/embed",
    json={
        "texts": ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"],
        "normalize": True,      # å‘é‡å½’ä¸€åŒ–
        "max_length": 512,      # æœ€å¤§é•¿åº¦ï¼ˆæ”¯æŒåˆ°8192ï¼‰
        "batch_size": 32        # æ‰¹å¤„ç†å¤§å°
    }
)

embeddings = response.json()["embeddings"]
# embeddings: List[List[float]], æ¯ä¸ªå‘é‡ 1024 ç»´
```

### è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦

```python
import numpy as np

def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2)  # å·²å½’ä¸€åŒ–ï¼Œç›´æ¥ç‚¹ç§¯

# è·å–åµŒå…¥
response = requests.post(..., json={
    "texts": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "],
    "normalize": True
})

vecs = response.json()["embeddings"]
similarity = cosine_similarity(vecs[0], vecs[1])
print(f"ç›¸ä¼¼åº¦: {similarity:.4f}")  # è¾“å‡º: 0.8523
```

---

## ğŸ“ é¡¹ç›®æ–‡ä»¶

```
/opt/bge-m3/
â”œâ”€â”€ serve_bge_m3.py              # ä¸»æœåŠ¡ï¼ˆå·²é…ç½®CPUæ¨¡å¼ï¼‰
â”œâ”€â”€ start_service.sh             # å¯åŠ¨è„šæœ¬ â­
â”œâ”€â”€ test_client.py               # æµ‹è¯•å®¢æˆ·ç«¯
â”œâ”€â”€ convert_to_safetensors.py   # æ ¼å¼è½¬æ¢å·¥å…·ï¼ˆå·²æ‰§è¡Œï¼‰
â”œâ”€â”€ QUICK_START.md              # æœ¬æ–‡æ¡£
â”œâ”€â”€ TROUBLESHOOTING.md          # å®Œæ•´æ•…éšœæ’æŸ¥
â””â”€â”€ models/bge-m3/
    â”œâ”€â”€ model.safetensors       # å®‰å…¨æ¨¡å‹æ ¼å¼ï¼ˆ2.2GBï¼‰
    â””â”€â”€ ...

```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Ÿ
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8001

# æ›´æ¢ç«¯å£
uvicorn serve_bge_m3:app --port 8002
```

### Q2: API è¿”å› 500 é”™è¯¯ï¼Ÿ
```bash
# æŸ¥çœ‹æ—¥å¿—
tail -f /tmp/bge_service.log
```

### Q3: å¦‚ä½•åœæ­¢æœåŠ¡ï¼Ÿ
```bash
pkill -f "uvicorn serve_bge_m3"
# æˆ–æŒ‰ Ctrl+Cï¼ˆå‰å°è¿è¡Œæ—¶ï¼‰
```

### Q4: å¦‚ä½•éªŒè¯ GPU æ˜¯å¦å·¥ä½œï¼Ÿ
```python
import torch
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"GPU åç§°: {torch.cuda.get_device_name(0)}")
```

---

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ•…éšœæ’æŸ¥**: æŸ¥çœ‹ `TROUBLESHOOTING.md`
- **ä½¿ç”¨æ–‡æ¡£**: æŸ¥çœ‹ `USAGE.md`
- **API æ–‡æ¡£**: è®¿é—® http://localhost:8001/docs
- **æ¨¡å‹è¯¦æƒ…**: https://huggingface.co/BAAI/bge-m3

---

**ğŸ‰ ç°åœ¨å°±å¼€å§‹ä½¿ç”¨å§ï¼**

```bash
./start_service.sh
```
